{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6a0a96-ebf3-408d-bdda-37ad5f68f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken as tk\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f284a20-9059-4898-803b-057711e5fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3a7691-cfdf-4ade-aeeb-73d97721a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Moby_Dick.txt\", \"r\",encoding=\"utf-8\") as f:\n",
    "    raw_text=f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b6c4d2-6d92-4eef-a948-57d4e8ee7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238224\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c012a7-5454-4989-8407-bb8bf07686d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##initilize the BPE tokenizer for gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc18ad32-ec55-4671-950f-8bfecfd7a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tk.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d54a842-bee3-41a2-93f5-017264b6559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##generating token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4188dc52-c430-4a89-846c-ede3b3b5d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids=tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a15d2ad-ca7f-4843-97b8-cdbd704c2c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331688\n"
     ]
    }
   ],
   "source": [
    "print(len(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57cd0467-566d-4222-82b0-e88d7dfcd84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc595a40-c70a-4fe3-82fa-f8e0b372edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_ids=[340, 11, 1577, 340, 1497, 393, 302, 12, 1904, 340, 739, 262, 2846, 198, 1659, 262, 4935, 20336, 13789, 3017, 351, 428, 47179, 393, 2691, 198, 265, 7324, 13, 70, 19028, 13, 2398, 13, 1002, 345, 389, 407, 5140, 287, 262, 1578, 1829, 11, 198, 5832, 481, 423, 284, 2198, 262, 3657, 286, 262, 1499, 810, 345, 389, 5140, 198, 19052, 1262, 428, 46566, 13, 198, 198, 19160, 25, 16540, 88, 11740, 26, 1471, 11, 383, 44772, 198, 198, 13838, 25, 25028, 5616, 4244, 198, 198, 26362, 3128, 25, 2901, 352, 11, 5878, 685, 68, 10482, 1303, 1983, 486, 60, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 4042, 2904]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393ad59d-a2a1-44c2-8c81-63697038c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decode method to decode the token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833635cd-fb9a-484d-a9c2-e0dcbda6d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_text=tokenizer.decode(tk_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98e89c8-f59a-4623-a684-c167ec1fc592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Title: Moby Dick; Or, The Whale\n",
      "\n",
      "Author: Herman Melville\n",
      "\n",
      "Release date: July 1, 2001 [eBook #2701]\n",
      "                Most recently\n"
     ]
    }
   ],
   "source": [
    "print(tk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd4cea73-8971-4c31-ac66-9d873665dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step2: Creating slind window for input and target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b75ea4-2cb5-4a1a-9f72-718b82340979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a dataset &dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668aa670-cdc9-4570-aa80-17406bf6fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4169345f-79d3-4b73-9a60-83918be561e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gptdataset(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_len,stride):\n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[]\n",
    "\n",
    "        token_ids_v1=tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids_v1)-max_len,stride):\n",
    "            input_chunk=token_ids_v1[i:i+max_len]\n",
    "            target_chunk=token_ids_v1[i+1:i+max_len+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "            return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d04fbba8-2d11-4b64-951e-c3507407bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a data loader to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95fc4270-76ab-44e4-b80a-5ff0e24781c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "def gpt_dataloader_v1(txt,batch_size=4,max_len=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    data_tokenizer=tk.get_encoding(\"gpt2\")\n",
    "    dataset=gptdataset(txt,data_tokenizer,max_len,stride)\n",
    "    dataloader=DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fbc22c1-c308-4cce-a299-7a468c30f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[15496,   995,     0,   770]]), tensor([[995,   0, 770, 318]])]\n"
     ]
    }
   ],
   "source": [
    "raw_text_1 = \"Hello world! This is a test sentence for GPT style dataset building.\"\n",
    "loader = gpt_dataloader_v1(raw_text_1, batch_size=1, max_len=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(loader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402979c3-8e1c-42c7-8604-be2b46b1aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LEts create vecoter embedding layer\n",
    "##embedding layer=token_embedding+postion_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b8ad2ad-416c-44b5-a830-fb5c8a43dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Token enbedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18b09e72-8a45-4ad0-87c9-afed04d2e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "vobac_size=50257\n",
    "tk_dimenison=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f214e2d9-db35-4367-b0f8-4ddde8bde50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b9cc2f5-0673-43c9-aa9f-f30678652f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding_layer=torch.nn.Embedding(vobac_size,tk_dimenison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54eefcc7-d680-4069-956c-408c6bccf81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50257, 256)\n"
     ]
    }
   ],
   "source": [
    "print(token_embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9140bf6-9c4a-4c76-9fe8-b48c0302d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=4\n",
    "dataloder=gpt_dataloader_v1(raw_text,batch_size=8,max_len=max_len,stride=4,shuffle=False)\n",
    "data_iter = iter(dataloder)\n",
    "inputs,target= next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c18d56b-bd49-403d-9135-94f1188cf966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  464,  4935, 20336, 46566],\n",
      "        [  286, 16540,    88, 11740],\n",
      "        [   26,  1471,    11,   383],\n",
      "        [44772,   198,   220,   220],\n",
      "        [  220,   220,   198,  1212],\n",
      "        [47179,   318,   329,   262],\n",
      "        [  779,   286,  2687,  6609],\n",
      "        [  287,   262,  1578,  1829]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97c148e7-a640-460f-af1d-c1174ac16c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_emdedding_layer_1=token_embedding_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d55d6405-d6b8-403b-9070-e0fee6b8c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(tk_emdedding_layer_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea31e833-2c95-4c07-9df5-843bd3a37b95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.5596,  1.4311, -0.4895,  ...,  0.2395,  1.0164, -1.4632],\n",
      "         [-0.8309, -0.1930,  0.6640,  ..., -0.0614,  0.9356, -0.3635],\n",
      "         [ 2.0100, -1.3733,  1.2970,  ..., -0.1645,  0.4183,  0.3888],\n",
      "         [-0.6540, -0.8189,  0.1852,  ..., -0.1721, -1.2283, -2.1277]],\n",
      "\n",
      "        [[-0.1072,  0.7699,  2.0443,  ..., -0.0854, -0.4407,  0.1447],\n",
      "         [-0.8679, -1.8907, -0.5414,  ..., -0.2159, -0.4577, -0.3753],\n",
      "         [ 0.2955, -0.8467, -0.4296,  ...,  0.8957, -1.3447,  0.2142],\n",
      "         [-0.2726, -0.3625,  0.5228,  ..., -0.2958,  0.6850, -0.0374]],\n",
      "\n",
      "        [[-0.5487, -0.0107, -0.5991,  ...,  2.3190,  0.4320, -0.6033],\n",
      "         [ 1.9045,  0.5762, -2.1534,  ...,  0.7203, -0.0501,  0.7268],\n",
      "         [-0.5882, -0.5428,  0.3933,  ..., -0.7051,  0.9897,  0.2720],\n",
      "         [ 1.3742, -0.0624,  0.9357,  ...,  0.9975, -1.6848,  0.8039]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4266, -1.0036,  0.2589,  ..., -0.2372,  1.2329, -1.1514],\n",
      "         [-0.3249, -0.1443, -1.1126,  ..., -0.0779,  1.9025,  1.8034],\n",
      "         [ 2.0504,  0.5645,  0.9297,  ..., -1.4826, -0.6687,  1.4460],\n",
      "         [ 1.0646,  0.2507,  0.7656,  ...,  0.5689,  1.3905, -1.0639]],\n",
      "\n",
      "        [[ 0.4092,  1.3044, -0.3297,  ...,  1.0683,  0.0122,  0.9407],\n",
      "         [-0.1072,  0.7699,  2.0443,  ..., -0.0854, -0.4407,  0.1447],\n",
      "         [ 1.7578, -0.0178, -0.4972,  ...,  0.2014, -0.1603, -1.3535],\n",
      "         [-0.3433, -0.9891,  1.5583,  ...,  2.0500, -1.5090, -0.1416]],\n",
      "\n",
      "        [[ 2.0839, -0.1521, -0.5613,  ..., -0.1370,  0.3659, -0.4537],\n",
      "         [ 1.0646,  0.2507,  0.7656,  ...,  0.5689,  1.3905, -1.0639],\n",
      "         [-1.9809, -0.5855,  3.3052,  ..., -1.0128,  1.1704,  1.1533],\n",
      "         [ 0.0441, -1.6023,  0.8884,  ..., -0.1757,  1.1970,  0.0360]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(tk_emdedding_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55ffe7dc-f093-4329-ab52-2f2470de8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LETS CREATE POSITIONAL EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "919e4594-1df3-49fc-b7ed-d4bd0fba8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_len=max_len\n",
    "pos_embeding=torch.nn.Embedding(context_len,tk_dimenison)\n",
    "pos_embedding_layer=pos_embeding(torch.arange(context_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "897b3ff7-bb0d-47c2-ae78-1118f733e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(pos_embedding_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56e1ec2b-57a3-4ca7-9f57-3b6c00982968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1566,  0.1960, -2.2551,  ...,  0.8173,  1.0112, -0.7442],\n",
      "        [-1.0004,  0.4385, -0.8315,  ..., -0.8623, -0.6163, -1.3550],\n",
      "        [-0.0060, -0.8635, -0.2049,  ...,  1.0794, -0.2802,  1.9901],\n",
      "        [-0.2212,  0.5660, -0.0865,  ...,  2.2350, -0.5586, -0.1718]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pos_embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a72c681-2d64-429b-8298-0b28cf16066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now lets create input embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65fac151-3769-430c-868b-84b3a7248585",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding_layer=tk_emdedding_layer_1+pos_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82b41ff7-6342-4f37-894b-1703a245ec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(input_embedding_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5b8b8e6-184b-4d29-81c5-fbe988b33284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4029,  1.6271, -2.7446,  ...,  1.0568,  2.0276, -2.2074],\n",
      "         [-1.8312,  0.2455, -0.1675,  ..., -0.9237,  0.3192, -1.7186],\n",
      "         [ 2.0040, -2.2367,  1.0921,  ...,  0.9149,  0.1381,  2.3789],\n",
      "         [-0.8753, -0.2529,  0.0987,  ...,  2.0628, -1.7869, -2.2995]],\n",
      "\n",
      "        [[-1.2638,  0.9659, -0.2109,  ...,  0.7319,  0.5705, -0.5995],\n",
      "         [-1.8683, -1.4523, -1.3729,  ..., -1.0782, -1.0740, -1.7303],\n",
      "         [ 0.2895, -1.7102, -0.6344,  ...,  1.9750, -1.6249,  2.2044],\n",
      "         [-0.4939,  0.2035,  0.4363,  ...,  1.9392,  0.1264, -0.2092]],\n",
      "\n",
      "        [[-1.7053,  0.1853, -2.8543,  ...,  3.1364,  1.4433, -1.3475],\n",
      "         [ 0.9042,  1.0146, -2.9848,  ..., -0.1420, -0.6665, -0.6282],\n",
      "         [-0.5943, -1.4063,  0.1885,  ...,  0.3743,  0.7095,  2.2622],\n",
      "         [ 1.1530,  0.5037,  0.8492,  ...,  3.2324, -2.2435,  0.6321]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7301, -0.8076, -1.9962,  ...,  0.5801,  2.2441, -1.8956],\n",
      "         [-1.3253,  0.2941, -1.9440,  ..., -0.9402,  1.2861,  0.4484],\n",
      "         [ 2.0444, -0.2989,  0.7249,  ..., -0.4032, -0.9489,  3.4361],\n",
      "         [ 0.8433,  0.8167,  0.6791,  ...,  2.8039,  0.8318, -1.2357]],\n",
      "\n",
      "        [[-0.7475,  1.5004, -2.5849,  ...,  1.8857,  1.0234,  0.1965],\n",
      "         [-1.1075,  1.2084,  1.2128,  ..., -0.9477, -1.0571, -1.2103],\n",
      "         [ 1.7517, -0.8813, -0.7020,  ...,  1.2807, -0.4405,  0.6366],\n",
      "         [-0.5645, -0.4231,  1.4718,  ...,  4.2850, -2.0677, -0.3134]],\n",
      "\n",
      "        [[ 0.9273,  0.0439, -2.8165,  ...,  0.6803,  1.3772, -1.1979],\n",
      "         [ 0.0642,  0.6892, -0.0659,  ..., -0.2934,  0.7742, -2.4190],\n",
      "         [-1.9869, -1.4490,  3.1004,  ...,  0.0665,  0.8902,  3.1434],\n",
      "         [-0.1771, -1.0363,  0.8019,  ...,  2.0593,  0.6384, -0.1357]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(input_embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc193132-a714-454c-af1f-701287614ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
